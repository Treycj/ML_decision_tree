{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72d727a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                         0\n",
       "Attrition                   0\n",
       "BusinessTravel              0\n",
       "DailyRate                   0\n",
       "Department                  0\n",
       "DistanceFromHome            0\n",
       "Education                   0\n",
       "EducationField              0\n",
       "EmployeeCount               0\n",
       "EmployeeNumber              0\n",
       "EnvironmentSatisfaction     0\n",
       "Gender                      0\n",
       "HourlyRate                  0\n",
       "JobInvolvement              0\n",
       "JobLevel                    0\n",
       "JobRole                     0\n",
       "JobSatisfaction             0\n",
       "MaritalStatus               0\n",
       "MonthlyIncome               0\n",
       "MonthlyRate                 0\n",
       "NumCompaniesWorked          0\n",
       "Over18                      0\n",
       "OverTime                    0\n",
       "PercentSalaryHike           0\n",
       "PerformanceRating           0\n",
       "RelationshipSatisfaction    0\n",
       "StandardHours               0\n",
       "StockOptionLevel            0\n",
       "TotalWorkingYears           0\n",
       "TrainingTimesLastYear       0\n",
       "WorkLifeBalance             0\n",
       "YearsAtCompany              0\n",
       "YearsInCurrentRole          0\n",
       "YearsSinceLastPromotion     0\n",
       "YearsWithCurrManager        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Exploratory Data Analysis (EDA)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report, confusion_matrix\n",
    "\n",
    "# Reading the dataset\n",
    "attrdata = pd.read_csv(\"employee_attrition_dataset.csv\")\n",
    "attrdata.head()\n",
    "\n",
    "# Dropping the index column\n",
    "attrdata.drop(0,inplace=True)\n",
    "\n",
    "# Returns all columns and shows the sum of null values in each column\n",
    "attrdata.isnull().sum()\n",
    "\n",
    "\n",
    "# if missing values drop them\n",
    "# attrdata.dropna(axis=0,inplace=True)\n",
    "# There are no missing values in my dataset\n",
    "\n",
    "# shape of my dataset\n",
    "# attrdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4348bf93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1470, 35)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report, confusion_matrix\n",
    "\n",
    "# Reading the dataset\n",
    "attrdata = pd.read_csv(\"employee_attrition_dataset.csv\")\n",
    "attrdata.head()\n",
    "\n",
    "# Dropping the index column\n",
    "# attrdata.drop(0,inplace=True)\n",
    "# attrdata.isnull().sum()\n",
    "\n",
    "# if missing values drop them\n",
    "# attrdata.dropna(axis=0,inplace=True)\n",
    "\n",
    "# shape of my dataset\n",
    "attrdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "923465ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age Attrition     BusinessTravel  DailyRate  DistanceFromHome  \\\n",
      "0      41       Yes      Travel_Rarely       1102                 1   \n",
      "1      49        No  Travel_Frequently        279                 8   \n",
      "2      37       Yes      Travel_Rarely       1373                 2   \n",
      "3      33        No  Travel_Frequently       1392                 3   \n",
      "4      27        No      Travel_Rarely        591                 2   \n",
      "...   ...       ...                ...        ...               ...   \n",
      "1465   36        No  Travel_Frequently        884                23   \n",
      "1466   39        No      Travel_Rarely        613                 6   \n",
      "1467   27        No      Travel_Rarely        155                 4   \n",
      "1468   49        No  Travel_Frequently       1023                 2   \n",
      "1469   34        No      Travel_Rarely        628                 8   \n",
      "\n",
      "      Education  EmployeeCount  EmployeeNumber  EnvironmentSatisfaction  \\\n",
      "0             2              1               1                        2   \n",
      "1             1              1               2                        3   \n",
      "2             2              1               4                        4   \n",
      "3             4              1               5                        4   \n",
      "4             1              1               7                        1   \n",
      "...         ...            ...             ...                      ...   \n",
      "1465          2              1            2061                        3   \n",
      "1466          1              1            2062                        4   \n",
      "1467          3              1            2064                        2   \n",
      "1468          3              1            2065                        4   \n",
      "1469          3              1            2068                        2   \n",
      "\n",
      "      HourlyRate  ...  JobRole_Sales Executive  JobRole_Sales Representative  \\\n",
      "0             94  ...                        1                             0   \n",
      "1             61  ...                        0                             0   \n",
      "2             92  ...                        0                             0   \n",
      "3             56  ...                        0                             0   \n",
      "4             40  ...                        0                             0   \n",
      "...          ...  ...                      ...                           ...   \n",
      "1465          41  ...                        0                             0   \n",
      "1466          42  ...                        0                             0   \n",
      "1467          87  ...                        0                             0   \n",
      "1468          63  ...                        1                             0   \n",
      "1469          82  ...                        0                             0   \n",
      "\n",
      "      Department_Research & Development  Department_Sales  \\\n",
      "0                                     0                 1   \n",
      "1                                     1                 0   \n",
      "2                                     1                 0   \n",
      "3                                     1                 0   \n",
      "4                                     1                 0   \n",
      "...                                 ...               ...   \n",
      "1465                                  1                 0   \n",
      "1466                                  1                 0   \n",
      "1467                                  1                 0   \n",
      "1468                                  0                 1   \n",
      "1469                                  1                 0   \n",
      "\n",
      "      EducationField_Life Sciences  EducationField_Marketing  \\\n",
      "0                                1                         0   \n",
      "1                                1                         0   \n",
      "2                                0                         0   \n",
      "3                                1                         0   \n",
      "4                                0                         0   \n",
      "...                            ...                       ...   \n",
      "1465                             0                         0   \n",
      "1466                             0                         0   \n",
      "1467                             1                         0   \n",
      "1468                             0                         0   \n",
      "1469                             0                         0   \n",
      "\n",
      "     EducationField_Medical EducationField_Other  \\\n",
      "0                         0                    0   \n",
      "1                         0                    0   \n",
      "2                         0                    1   \n",
      "3                         0                    0   \n",
      "4                         1                    0   \n",
      "...                     ...                  ...   \n",
      "1465                      1                    0   \n",
      "1466                      1                    0   \n",
      "1467                      0                    0   \n",
      "1468                      1                    0   \n",
      "1469                      1                    0   \n",
      "\n",
      "      EducationField_Technical Degree  Gender_Male  \n",
      "0                                   0            0  \n",
      "1                                   0            1  \n",
      "2                                   0            1  \n",
      "3                                   0            0  \n",
      "4                                   0            1  \n",
      "...                               ...          ...  \n",
      "1465                                0            1  \n",
      "1466                                0            1  \n",
      "1467                                0            1  \n",
      "1468                                0            1  \n",
      "1469                                0            1  \n",
      "\n",
      "[1470 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "# Exploring categorical values\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Reading the dataset\n",
    "attrdata = pd.read_csv(\"employee_attrition_dataset.csv\")\n",
    "attrdata.head()\n",
    "\n",
    "df = pd.DataFrame(attrdata)\n",
    "\n",
    "\n",
    "# Encode categorical values\n",
    "# One-Hot Encoding for nominal data\n",
    "\n",
    "# Convert categorical variables with nominal data (no intrinsic order) into binary vectors.\n",
    "# Each category becomes a binary feature column (0 or 1).\n",
    "# The ordinal data “Education” was already encoded so I decided to go with what was given in the dataset.\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Gender','MaritalStatus','JobRole','Department', 'EducationField', 'Gender'], drop_first=True)\n",
    "# print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2778ec62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Age Attrition     BusinessTravel  DailyRate  DistanceFromHome  \\\n",
      "0     0.446350       Yes      Travel_Rarely   0.742527         -1.010909   \n",
      "1     1.322365        No  Travel_Frequently  -1.297775         -0.147150   \n",
      "2     0.008343       Yes      Travel_Rarely   1.414363         -0.887515   \n",
      "3    -0.429664        No  Travel_Frequently   1.461466         -0.764121   \n",
      "4    -1.086676        No      Travel_Rarely  -0.524295         -0.887515   \n",
      "...        ...       ...                ...        ...               ...   \n",
      "1465 -0.101159        No  Travel_Frequently   0.202082          1.703764   \n",
      "1466  0.227347        No      Travel_Rarely  -0.469754         -0.393938   \n",
      "1467 -1.086676        No      Travel_Rarely  -1.605183         -0.640727   \n",
      "1468  1.322365        No  Travel_Frequently   0.546677         -0.887515   \n",
      "1469 -0.320163        No      Travel_Rarely  -0.432568         -0.147150   \n",
      "\n",
      "      Education  EmployeeCount  EmployeeNumber  EnvironmentSatisfaction  \\\n",
      "0             2              1       -1.701283                        2   \n",
      "1             1              1       -1.699621                        3   \n",
      "2             2              1       -1.696298                        4   \n",
      "3             4              1       -1.694636                        4   \n",
      "4             1              1       -1.691313                        1   \n",
      "...         ...            ...             ...                      ...   \n",
      "1465          2              1        1.721670                        3   \n",
      "1466          1              1        1.723332                        4   \n",
      "1467          3              1        1.726655                        2   \n",
      "1468          3              1        1.728317                        4   \n",
      "1469          3              1        1.733302                        2   \n",
      "\n",
      "      HourlyRate  ...  JobRole_Sales Executive  JobRole_Sales Representative  \\\n",
      "0       1.383138  ...                        1                             0   \n",
      "1      -0.240677  ...                        0                             0   \n",
      "2       1.284725  ...                        0                             0   \n",
      "3      -0.486709  ...                        0                             0   \n",
      "4      -1.274014  ...                        0                             0   \n",
      "...          ...  ...                      ...                           ...   \n",
      "1465   -1.224807  ...                        0                             0   \n",
      "1466   -1.175601  ...                        0                             0   \n",
      "1467    1.038693  ...                        0                             0   \n",
      "1468   -0.142264  ...                        1                             0   \n",
      "1469    0.792660  ...                        0                             0   \n",
      "\n",
      "      Department_Research & Development  Department_Sales  \\\n",
      "0                                     0                 1   \n",
      "1                                     1                 0   \n",
      "2                                     1                 0   \n",
      "3                                     1                 0   \n",
      "4                                     1                 0   \n",
      "...                                 ...               ...   \n",
      "1465                                  1                 0   \n",
      "1466                                  1                 0   \n",
      "1467                                  1                 0   \n",
      "1468                                  0                 1   \n",
      "1469                                  1                 0   \n",
      "\n",
      "      EducationField_Life Sciences  EducationField_Marketing  \\\n",
      "0                                1                         0   \n",
      "1                                1                         0   \n",
      "2                                0                         0   \n",
      "3                                1                         0   \n",
      "4                                0                         0   \n",
      "...                            ...                       ...   \n",
      "1465                             0                         0   \n",
      "1466                             0                         0   \n",
      "1467                             1                         0   \n",
      "1468                             0                         0   \n",
      "1469                             0                         0   \n",
      "\n",
      "     EducationField_Medical EducationField_Other  \\\n",
      "0                         0                    0   \n",
      "1                         0                    0   \n",
      "2                         0                    1   \n",
      "3                         0                    0   \n",
      "4                         1                    0   \n",
      "...                     ...                  ...   \n",
      "1465                      1                    0   \n",
      "1466                      1                    0   \n",
      "1467                      0                    0   \n",
      "1468                      1                    0   \n",
      "1469                      1                    0   \n",
      "\n",
      "      EducationField_Technical Degree  Gender_Male  \n",
      "0                                   0            0  \n",
      "1                                   0            1  \n",
      "2                                   0            1  \n",
      "3                                   0            0  \n",
      "4                                   0            1  \n",
      "...                               ...          ...  \n",
      "1465                                0            1  \n",
      "1466                                0            1  \n",
      "1467                                0            1  \n",
      "1468                                0            1  \n",
      "1469                                0            1  \n",
      "\n",
      "[1470 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "# Scaling Numerical Features\n",
    "# Scaling numerical features ensures that all features contribute equally to the model's performance and helps prevent some algorithms from being dominated by features with larger scales.You use  standardization when the dataset follows a normal distribution which I believe is the case for this dataset. These are the scaling features that I used for my dataset:\n",
    "# a. Standardization (Z-score scaling):\n",
    "# Transform features to have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "# b. Min-Max Scaling:\n",
    "# Rescale features to a specified range, typically [0, 1].\n",
    "\n",
    "# Standardization (Z-score scaling)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Reading the dataset\n",
    "attrdata = pd.read_csv(\"employee_attrition_dataset.csv\")\n",
    "attrdata.head()\n",
    "\n",
    "df = pd.DataFrame(attrdata)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Gender','MaritalStatus','JobRole','Department', 'EducationField', 'Gender'], drop_first=True)\n",
    "\n",
    "df[['Age','DailyRate','MonthlyIncome','DistanceFromHome','HourlyRate','EmployeeNumber','MonthlyRate','PercentSalaryHike','StandardHours','TotalWorkingYears']] = scaler.fit_transform(df[['Age','DailyRate','MonthlyIncome','DistanceFromHome','HourlyRate','EmployeeNumber','MonthlyRate','PercentSalaryHike','StandardHours','TotalWorkingYears']])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b27e440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Age Attrition     BusinessTravel  DailyRate  DistanceFromHome  \\\n",
      "0     0.547619       Yes      Travel_Rarely   0.715820          0.000000   \n",
      "1     0.738095        No  Travel_Frequently   0.126700          0.250000   \n",
      "2     0.452381       Yes      Travel_Rarely   0.909807          0.035714   \n",
      "3     0.357143        No  Travel_Frequently   0.923407          0.071429   \n",
      "4     0.214286        No      Travel_Rarely   0.350036          0.035714   \n",
      "...        ...       ...                ...        ...               ...   \n",
      "1465  0.428571        No  Travel_Frequently   0.559771          0.785714   \n",
      "1466  0.500000        No      Travel_Rarely   0.365784          0.178571   \n",
      "1467  0.214286        No      Travel_Rarely   0.037938          0.107143   \n",
      "1468  0.738095        No  Travel_Frequently   0.659270          0.035714   \n",
      "1469  0.380952        No      Travel_Rarely   0.376521          0.250000   \n",
      "\n",
      "      Education  EmployeeCount  EmployeeNumber  EnvironmentSatisfaction  \\\n",
      "0             2              1        0.000000                        2   \n",
      "1             1              1        0.000484                        3   \n",
      "2             2              1        0.001451                        4   \n",
      "3             4              1        0.001935                        4   \n",
      "4             1              1        0.002903                        1   \n",
      "...         ...            ...             ...                      ...   \n",
      "1465          2              1        0.996613                        3   \n",
      "1466          1              1        0.997097                        4   \n",
      "1467          3              1        0.998065                        2   \n",
      "1468          3              1        0.998549                        4   \n",
      "1469          3              1        1.000000                        2   \n",
      "\n",
      "      HourlyRate  ...  JobRole_Sales Executive  JobRole_Sales Representative  \\\n",
      "0       0.914286  ...                        1                             0   \n",
      "1       0.442857  ...                        0                             0   \n",
      "2       0.885714  ...                        0                             0   \n",
      "3       0.371429  ...                        0                             0   \n",
      "4       0.142857  ...                        0                             0   \n",
      "...          ...  ...                      ...                           ...   \n",
      "1465    0.157143  ...                        0                             0   \n",
      "1466    0.171429  ...                        0                             0   \n",
      "1467    0.814286  ...                        0                             0   \n",
      "1468    0.471429  ...                        1                             0   \n",
      "1469    0.742857  ...                        0                             0   \n",
      "\n",
      "      Department_Research & Development  Department_Sales  \\\n",
      "0                                     0                 1   \n",
      "1                                     1                 0   \n",
      "2                                     1                 0   \n",
      "3                                     1                 0   \n",
      "4                                     1                 0   \n",
      "...                                 ...               ...   \n",
      "1465                                  1                 0   \n",
      "1466                                  1                 0   \n",
      "1467                                  1                 0   \n",
      "1468                                  0                 1   \n",
      "1469                                  1                 0   \n",
      "\n",
      "      EducationField_Life Sciences  EducationField_Marketing  \\\n",
      "0                                1                         0   \n",
      "1                                1                         0   \n",
      "2                                0                         0   \n",
      "3                                1                         0   \n",
      "4                                0                         0   \n",
      "...                            ...                       ...   \n",
      "1465                             0                         0   \n",
      "1466                             0                         0   \n",
      "1467                             1                         0   \n",
      "1468                             0                         0   \n",
      "1469                             0                         0   \n",
      "\n",
      "     EducationField_Medical EducationField_Other  \\\n",
      "0                         0                    0   \n",
      "1                         0                    0   \n",
      "2                         0                    1   \n",
      "3                         0                    0   \n",
      "4                         1                    0   \n",
      "...                     ...                  ...   \n",
      "1465                      1                    0   \n",
      "1466                      1                    0   \n",
      "1467                      0                    0   \n",
      "1468                      1                    0   \n",
      "1469                      1                    0   \n",
      "\n",
      "      EducationField_Technical Degree  Gender_Male  \n",
      "0                                   0            0  \n",
      "1                                   0            1  \n",
      "2                                   0            1  \n",
      "3                                   0            0  \n",
      "4                                   0            1  \n",
      "...                               ...          ...  \n",
      "1465                                0            1  \n",
      "1466                                0            1  \n",
      "1467                                0            1  \n",
      "1468                                0            1  \n",
      "1469                                0            1  \n",
      "\n",
      "[1470 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "# Using min-max scaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Reading the dataset\n",
    "attrdata = pd.read_csv(\"employee_attrition_dataset.csv\")\n",
    "attrdata.head()\n",
    "\n",
    "df = pd.DataFrame(attrdata)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Gender','MaritalStatus','JobRole','Department', 'EducationField', 'Gender'], drop_first=True)\n",
    "\n",
    "df[['Age','DailyRate','MonthlyIncome','DistanceFromHome','HourlyRate','EmployeeNumber','MonthlyRate','PercentSalaryHike','StandardHours','TotalWorkingYears']] = scaler.fit_transform(df[['Age','DailyRate','MonthlyIncome','DistanceFromHome','HourlyRate','EmployeeNumber','MonthlyRate','PercentSalaryHike','StandardHours','TotalWorkingYears']])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74aceb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Features:\n",
      "                              Feature  Mutual_Info_Score\n",
      "21                   StockOptionLevel           0.032184\n",
      "14                      MonthlyIncome           0.030660\n",
      "12                           JobLevel           0.029989\n",
      "3                                 Age           0.027283\n",
      "2                        OverTime_Yes           0.023578\n",
      "40       JobRole_Sales Representative           0.020894\n",
      "22                  TotalWorkingYears           0.020779\n",
      "27            YearsSinceLastPromotion           0.019419\n",
      "32               MaritalStatus_Single           0.016636\n",
      "46               EducationField_Other           0.013695\n",
      "36     JobRole_Manufacturing Director           0.012635\n",
      "10                         HourlyRate           0.011592\n",
      "26                 YearsInCurrentRole           0.011438\n",
      "28               YearsWithCurrManager           0.010887\n",
      "37          JobRole_Research Director           0.010210\n",
      "11                     JobInvolvement           0.009849\n",
      "0    BusinessTravel_Travel_Frequently           0.009126\n",
      "35                    JobRole_Manager           0.008740\n",
      "8                      EmployeeNumber           0.008268\n",
      "25                     YearsAtCompany           0.006452\n",
      "44           EducationField_Marketing           0.005540\n",
      "24                    WorkLifeBalance           0.005121\n",
      "49                        Gender_Male           0.004665\n",
      "42                   Department_Sales           0.004386\n",
      "43       EducationField_Life Sciences           0.003957\n",
      "33            JobRole_Human Resources           0.003760\n",
      "31              MaritalStatus_Married           0.003612\n",
      "47    EducationField_Technical Degree           0.003452\n",
      "34      JobRole_Laboratory Technician           0.002754\n",
      "15                        MonthlyRate           0.002202\n",
      "4                           DailyRate           0.002083\n",
      "30                        Gender_Male           0.001144\n",
      "39            JobRole_Sales Executive           0.000324\n",
      "41  Department_Research & Development           0.000265\n",
      "45             EducationField_Medical           0.000000\n",
      "38         JobRole_Research Scientist           0.000000\n",
      "48                        Gender_Male           0.000000\n",
      "5                    DistanceFromHome           0.000000\n",
      "20                      StandardHours           0.000000\n",
      "6                           Education           0.000000\n",
      "7                       EmployeeCount           0.000000\n",
      "19           RelationshipSatisfaction           0.000000\n",
      "13                    JobSatisfaction           0.000000\n",
      "29                        Gender_Male           0.000000\n",
      "16                 NumCompaniesWorked           0.000000\n",
      "17                  PercentSalaryHike           0.000000\n",
      "1        BusinessTravel_Travel_Rarely           0.000000\n",
      "23              TrainingTimesLastYear           0.000000\n",
      "18                  PerformanceRating           0.000000\n",
      "9             EnvironmentSatisfaction           0.000000\n"
     ]
    }
   ],
   "source": [
    "# Applying feature selection techniques\n",
    "# I decided to use two techniques Correlation-based Feature Selection (CFS) and Feature Importance from Tree-Based Models\n",
    "\n",
    "# Correlation-based Feature Selection (CFS)\n",
    "# CFS evaluates the correlation between each feature and the target variable (in this case, attrition) and selects features with high correlations.\n",
    "# It helps in choosing features that have the most impact on the target variable.\n",
    "\n",
    "# Reasons for choosing Correlation-based Feature Selection\n",
    "# Dimensionality Reduction: By selecting a subset of relevant features, CFS reduces the dimensionality of the dataset. This can lead to simpler and more interpretable models and may improve model performance.\n",
    "# Improved Model Performance: CFS can help improve model accuracy and generalization by removing noisy or irrelevant features that can introduce noise and overfitting.\n",
    "# Computational Efficiency: When dealing with high-dimensional datasets, reducing the number of features can significantly speed up the training and testing of machine learning models.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "\n",
    "# Reading the dataset\n",
    "attrdata = pd.read_csv(\"employee_attrition_dataset.csv\")\n",
    "attrdata.head()\n",
    "\n",
    "df = pd.DataFrame(attrdata)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Gender','MaritalStatus','JobRole','Department', 'EducationField', 'Gender'], drop_first=True)\n",
    "\n",
    "df[['Age','DailyRate','MonthlyIncome','DistanceFromHome','HourlyRate','EmployeeNumber','MonthlyRate','PercentSalaryHike','StandardHours','TotalWorkingYears']] = scaler.fit_transform(df[['Age','DailyRate','MonthlyIncome','DistanceFromHome','HourlyRate','EmployeeNumber','MonthlyRate','PercentSalaryHike','StandardHours','TotalWorkingYears']])\n",
    "\n",
    "# print(df)\n",
    "\n",
    "# Taking \"Attrition\" as the target variable\n",
    "X = df.drop(columns=[\"Attrition\"])\n",
    "y = df[\"Attrition\"]\n",
    "\n",
    "# Separate categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "numerical_cols = X.select_dtypes(exclude=[\"object\"]).columns\n",
    "\n",
    "# Encode categorical columns with one-hot encoding\n",
    "encoder = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
    "X_encoded = encoder.fit_transform(X[categorical_cols])\n",
    "\n",
    "# Combining one-hot encoded categorical features with numerical features\n",
    "X_encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "X = pd.concat([X_encoded_df, X[numerical_cols]], axis=1)\n",
    "\n",
    "# Calculating mutual information between each feature and the target variable\n",
    "mutual_info = SelectKBest(score_func=mutual_info_classif, k=\"all\")\n",
    "mutual_info.fit(X, y)\n",
    "\n",
    "# Geting feature scores and names\n",
    "feature_scores = mutual_info.scores_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Creating a DataFrame to display feature scores\n",
    "feature_scores_df = pd.DataFrame({\"Feature\": feature_names, \"Mutual_Info_Score\": feature_scores})\n",
    "\n",
    "# Sorting features by their mutual information scores in descending order\n",
    "feature_scores_df = feature_scores_df.sort_values(by=\"Mutual_Info_Score\", ascending=False)\n",
    "\n",
    "# Display the top features\n",
    "print(\"Top Features:\")\n",
    "print(feature_scores_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebd86126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Features:\n",
      "                              Feature  Importance\n",
      "11                      MonthlyIncome    0.068898\n",
      "0                                 Age    0.059961\n",
      "46                       OverTime_Yes    0.050943\n",
      "19                  TotalWorkingYears    0.049634\n",
      "1                           DailyRate    0.047731\n",
      "5                      EmployeeNumber    0.046512\n",
      "12                        MonthlyRate    0.044772\n",
      "7                          HourlyRate    0.043848\n",
      "2                    DistanceFromHome    0.041712\n",
      "22                     YearsAtCompany    0.038886\n",
      "14                  PercentSalaryHike    0.033047\n",
      "13                 NumCompaniesWorked    0.031584\n",
      "18                   StockOptionLevel    0.029796\n",
      "25               YearsWithCurrManager    0.028459\n",
      "23                 YearsInCurrentRole    0.027325\n",
      "10                    JobSatisfaction    0.026676\n",
      "6             EnvironmentSatisfaction    0.026056\n",
      "20              TrainingTimesLastYear    0.025213\n",
      "21                    WorkLifeBalance    0.023321\n",
      "9                            JobLevel    0.022872\n",
      "8                      JobInvolvement    0.022619\n",
      "16           RelationshipSatisfaction    0.022072\n",
      "24            YearsSinceLastPromotion    0.021811\n",
      "3                           Education    0.018257\n",
      "45               MaritalStatus_Single    0.013918\n",
      "26   BusinessTravel_Travel_Frequently    0.013876\n",
      "44              MaritalStatus_Married    0.009222\n",
      "28  Department_Research & Development    0.009201\n",
      "37      JobRole_Laboratory Technician    0.009121\n",
      "35                        Gender_Male    0.009075\n",
      "32             EducationField_Medical    0.008763\n",
      "29                   Department_Sales    0.007773\n",
      "42            JobRole_Sales Executive    0.007770\n",
      "43       JobRole_Sales Representative    0.007619\n",
      "34    EducationField_Technical Degree    0.007445\n",
      "41         JobRole_Research Scientist    0.007327\n",
      "31           EducationField_Marketing    0.006948\n",
      "30       EducationField_Life Sciences    0.006883\n",
      "27       BusinessTravel_Travel_Rarely    0.006856\n",
      "15                  PerformanceRating    0.004992\n",
      "33               EducationField_Other    0.003255\n",
      "36            JobRole_Human Resources    0.002963\n",
      "39     JobRole_Manufacturing Director    0.002919\n",
      "38                    JobRole_Manager    0.001276\n",
      "40          JobRole_Research Director    0.000794\n",
      "4                       EmployeeCount    0.000000\n",
      "17                      StandardHours    0.000000\n"
     ]
    }
   ],
   "source": [
    "# Using feature Importance from Tree-Based Models\n",
    "\n",
    "# Feature importance refers to a technique that assigns a score to features based on how significant they are at predicting a target variable. \n",
    "# The scores are calculated on the weighted Gini indices. Easy way to obtain the scores is by using the feature_importances_ attribute from the trained tree model\n",
    "\n",
    "# Reasons for choosing Feature Importance from Tree-Based Models\n",
    "# Identification of Relevant Features: Tree-based models, such as Random Forest and Gradient Boosting, can effectively identify which features have the most significant impact on the target variable. This helps in focusing on the most informative attributes for prediction.\n",
    "# Ranking of Features: Feature importance scores provide a ranked list of features, allowing you to prioritize and select the most influential ones. This can simplify model interpretation and guide feature selection efforts.\n",
    "# Automatic Feature Selection: Feature importance allows you to automate the feature selection process. By setting a threshold or selecting the top N features, you can reduce the dimensionality of the dataset without manual intervention.\n",
    "# Reduced Overfitting: Selecting relevant features can help reduce overfitting in machine learning models. When you remove less informative or noisy features, the model becomes more robust and better generalizes to new data.\n",
    "# Improved Model Performance: Focusing on the most important features often leads to improved model performance. By reducing the number of irrelevant or redundant features, the model can learn from the most relevant information, resulting in better accuracy and generalization.\n",
    "# Efficient Computation: Tree-based models can efficiently calculate feature importances during training, making it a relatively fast and scalable method for feature selection even with large datasets.\n",
    "# Insight into Data Relationships: Feature importance scores can provide insights into the relationships between features and the target variable. This can help you gain a better understanding of the data and the factors driving the predictions.\n",
    "# Interpretability: Feature importance is easy to interpret. It allows you to explain to stakeholders or non-technical users which features are the most critical in making predictions, enhancing the transparency of your model.\n",
    "# Use in Ensemble Methods: Tree-based models are often used as base learners in ensemble methods like stacking and AdaBoost. By selecting features based on importance in these base models, you can improve the performance of ensemble models.\n",
    "# Feature Engineering Guidance: Feature importance can guide feature engineering efforts. It helps you focus on enhancing or creating features that are highly relevant to the target variable.\n",
    "# Model Debugging: When a model is not performing as expected, feature importance analysis can reveal which features might be causing issues or contributing to model errors.\n",
    "# Use in Dimensionality Reduction: Feature importance scores can be used as a criterion for dimensionality reduction techniques like Principal Component Analysis (PCA). Features with low importance may be candidates for removal in PCA.\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Reading the dataset\n",
    "attrdata = pd.read_csv(\"employee_attrition_dataset.csv\")\n",
    "attrdata.head()\n",
    "\n",
    "df = pd.DataFrame(attrdata)\n",
    "\n",
    "# Taking \"Attrition\" as the target variable\n",
    "X = df.drop(columns=[\"Attrition\"])\n",
    "y = df[\"Attrition\"]\n",
    "\n",
    "# Convert categorical variables to numerical using one-hot encoding\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Initialize a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fitting the model to the data\n",
    "rf_classifier.fit(X, y)\n",
    "\n",
    "# Geting feature importances\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "\n",
    "# Creating a DataFrame to display feature importances\n",
    "feature_importance_df = pd.DataFrame({\"Feature\": X.columns, \"Importance\": feature_importances})\n",
    "\n",
    "# Sorting features by importance in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Display the top features\n",
    "print(\"Top Features:\")\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dda8e03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1176, 47)\n",
      "X_test shape: (294, 47)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset\n",
    "\n",
    "# After encoding the features and calculating mutual information scores, we split the data into training and testing sets using train_test_split. The test_size parameter specifies the proportion of the dataset to include in the testing set (20% in this case).\n",
    "# We assign the resulting training and testing sets to X_train, X_test, y_train, and y_test.\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Reading the dataset\n",
    "attrdata = pd.read_csv(\"employee_attrition_dataset.csv\")\n",
    "attrdata.head()\n",
    "\n",
    "df = pd.DataFrame(attrdata)\n",
    "\n",
    "# Taking \"Attrition\" as the target variable\n",
    "X = df.drop(columns=[\"Attrition\"])\n",
    "y = df[\"Attrition\"]\n",
    "\n",
    "# Separate categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "numerical_cols = X.select_dtypes(exclude=[\"object\"]).columns\n",
    "\n",
    "# Encode categorical columns with one-hot encoding\n",
    "encoder = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
    "X_encoded = encoder.fit_transform(X[categorical_cols])\n",
    "\n",
    "# Combine one-hot encoded categorical features with numerical features\n",
    "X_encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "X = pd.concat([X_encoded_df, X[numerical_cols]], axis=1)\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.head()\n",
    "\n",
    "\n",
    "# Calculate mutual information between each feature and the target variable using the training set\n",
    "mutual_info = SelectKBest(score_func=mutual_info_classif, k=\"all\")\n",
    "mutual_info.fit(X_train, y_train)\n",
    "\n",
    "# Get feature scores and names\n",
    "feature_scores = mutual_info.scores_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create a DataFrame to display feature scores\n",
    "feature_scores_df = pd.DataFrame({\"Feature\": feature_names, \"Mutual_Info_Score\": feature_scores})\n",
    "\n",
    "# Sort features by their mutual information scores in descending order\n",
    "feature_scores_df = feature_scores_df.sort_values(by=\"Mutual_Info_Score\", ascending=False)\n",
    "\n",
    "# Display the top features\n",
    "# print(\"Top Features:\")\n",
    "# print(feature_scores_df)\n",
    "\n",
    "# printing training and testing sets shape respectfully\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be9f2c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.88      0.87      0.87       255\n",
      "         Yes       0.19      0.21      0.20        39\n",
      "\n",
      "    accuracy                           0.78       294\n",
      "   macro avg       0.53      0.54      0.53       294\n",
      "weighted avg       0.79      0.78      0.78       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Building and Evaluation\n",
    "\n",
    "# Using a Decision Tree Classification Algorithm\n",
    "\n",
    "# During training, the Decision Tree algorithm selects the best attribute to split the data based on a metric such as entropy or Gini impurity, which measures the level of impurity or randomness in the subsets.\n",
    "# The goal is to find the attribute that maximizes the information gain or the reduction in impurity after the split.\n",
    "\n",
    "# The script below calculates the accuracy of the model's prediction,\n",
    "# displays a classification report that includes precision,recall, F1-sscore and support for both classes(\"Attrition\" and \"No Attrition\")\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Reading the dataset\n",
    "attrdata = pd.read_csv(\"employee_attrition_dataset.csv\")\n",
    "attrdata.head()\n",
    "\n",
    "df = pd.DataFrame(attrdata)\n",
    "\n",
    "# Taking \"Attrition\" as the target variable\n",
    "X = df.drop(columns=[\"Attrition\"])\n",
    "y = df[\"Attrition\"]\n",
    "\n",
    "# Separate categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "numerical_cols = X.select_dtypes(exclude=[\"object\"]).columns\n",
    "\n",
    "# Encode categorical columns with one-hot encoding\n",
    "encoder = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
    "X_encoded = encoder.fit_transform(X[categorical_cols])\n",
    "\n",
    "# Combine one-hot encoded categorical features with numerical features\n",
    "X_encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "X = pd.concat([X_encoded_df, X[numerical_cols]], axis=1)\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.head()\n",
    "\n",
    "\n",
    "# Calculate mutual information between each feature and the target variable using the training set\n",
    "mutual_info = SelectKBest(score_func=mutual_info_classif, k=\"all\")\n",
    "mutual_info.fit(X_train, y_train)\n",
    "\n",
    "# Get feature scores and names\n",
    "feature_scores = mutual_info.scores_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create a DataFrame to display feature scores\n",
    "feature_scores_df = pd.DataFrame({\"Feature\": feature_names, \"Mutual_Info_Score\": feature_scores})\n",
    "\n",
    "# Sort features by their mutual information scores in descending order\n",
    "feature_scores_df = feature_scores_df.sort_values(by=\"Mutual_Info_Score\", ascending=False)\n",
    "\n",
    "# Display the top features\n",
    "# print(\"Top Features:\")\n",
    "# print(feature_scores_df)\n",
    "\n",
    "# printing training and testing sets shape respectfully\n",
    "# print(f\"X_train shape: {X_train.shape}\")\n",
    "# print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "# Train a Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Display classification report (includes precision, recall, F1-score, and support)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97c06ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores:\n",
      "[0.85169492 0.82978723 0.82978723 0.8212766  0.82553191]\n",
      "Accuracy on Test Set: 0.80\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.87      0.89      0.88       255\n",
      "         Yes       0.18      0.15      0.17        39\n",
      "\n",
      "    accuracy                           0.80       294\n",
      "   macro avg       0.53      0.52      0.53       294\n",
      "weighted avg       0.78      0.80      0.79       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using cross validation to optimize performance\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Reading the dataset\n",
    "attrdata = pd.read_csv(\"employee_attrition_dataset.csv\")\n",
    "attrdata.head()\n",
    "\n",
    "df = pd.DataFrame(attrdata)\n",
    "\n",
    "# Taking \"Attrition\" as the target variable\n",
    "X = df.drop(columns=[\"Attrition\"])\n",
    "y = df[\"Attrition\"]\n",
    "\n",
    "# Separate categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "numerical_cols = X.select_dtypes(exclude=[\"object\"]).columns\n",
    "\n",
    "# Encode categorical columns with one-hot encoding\n",
    "encoder = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
    "X_encoded = encoder.fit_transform(X[categorical_cols])\n",
    "\n",
    "# Combine one-hot encoded categorical features with numerical features\n",
    "X_encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "X = pd.concat([X_encoded_df, X[numerical_cols]], axis=1)\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.head()\n",
    "\n",
    "# Calculate mutual information between each feature and the target variable using the training set\n",
    "mutual_info = SelectKBest(score_func=mutual_info_classif, k=\"all\")\n",
    "mutual_info.fit(X_train, y_train)\n",
    "\n",
    "# Get feature scores and names\n",
    "feature_scores = mutual_info.scores_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create a DataFrame to display feature scores\n",
    "feature_scores_df = pd.DataFrame({\"Feature\": feature_names, \"Mutual_Info_Score\": feature_scores})\n",
    "\n",
    "# Sort features by their mutual information scores in descending order\n",
    "feature_scores_df = feature_scores_df.sort_values(by=\"Mutual_Info_Score\", ascending=False)\n",
    "\n",
    "# Display the top features\n",
    "# print(\"Top Features:\")\n",
    "# print(feature_scores_df)\n",
    "\n",
    "# printing training and testing sets shape respectfully\n",
    "# print(f\"X_train shape: {X_train.shape}\")\n",
    "# print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "# Define a Decision Tree Classifier\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Perform cross-validation with GridSearchCV for hyperparameter tuning\n",
    "param_grid = {\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [None, \"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring=\"accuracy\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Perform cross-validation with the best model\n",
    "cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "# Display cross-validation scores\n",
    "print(\"Cross-Validation Scores:\")\n",
    "print(cv_scores)\n",
    "\n",
    "# Train the best model on the entire training set\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on Test Set: {accuracy:.2f}\")\n",
    "\n",
    "# Display classification report (includes precision, recall, F1-score, and support)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e749c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80\n",
      "Precision: 0.18\n",
      "Recall: 0.15\n",
      "F1-score: 0.17\n",
      "ROC-AUC: 0.57\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model Training, Testing, and Evaluation\n",
    "\n",
    "# Using the trained Decision Tree Classifier model to make predictions on the test dataset, \n",
    "# evaluate its performance using appropriate metrics, and visualize its performance with a confusion matrix.\n",
    "\n",
    "# I calculate various performance metrics:\n",
    "# Accuracy: Measures the overall correctness of predictions.\n",
    "# Precision: Measures the proportion of true positive predictions among all positive predictions.\n",
    "# Recall: Measures the proportion of true positive predictions among all actual positives.\n",
    "# F1-score: The harmonic mean of precision and recall.\n",
    "# ROC-AUC: Measures the area under the Receiver Operating Characteristic (ROC) curve, indicating the model's ability to distinguish between classes.\n",
    "# The confusion matrix shows the count of true positives, false positives, true negatives, and false negatives.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "\n",
    "# Making predictions on the test set using the trained model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculating and printing model performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=\"Yes\")\n",
    "recall = recall_score(y_test, y_pred, pos_label=\"Yes\")\n",
    "f1 = f1_score(y_test, y_pred, pos_label=\"Yes\")\n",
    "roc_auc = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.2f}\")\n",
    "\n",
    "# Visualizing the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "labels = [\"No Attrition\", \"Attrition\"]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(conf_matrix, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "ax.set(xticks=np.arange(conf_matrix.shape[1]),\n",
    "       yticks=np.arange(conf_matrix.shape[0]),\n",
    "       xticklabels=labels, yticklabels=labels,\n",
    "       title=\"Confusion Matrix\",\n",
    "       ylabel=\"Actual label\",\n",
    "       xlabel=\"Predicted label\")\n",
    "\n",
    "# Adding text annotations to the confusion matrix\n",
    "thresh = conf_matrix.max() / 2.\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(j, i, format(conf_matrix[i, j], \"d\"),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321f05d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insights\n",
    "# The accuracy is quite high which is good. However we cannot rely on accuracy alone for model evaluation especially in imbalanced datasets.\n",
    "# The Precision is quite high which indicates fewer cases of false positives in the model's prediction.\n",
    "# The Recall is quite high which indicates that our model predicted fewer false negatives.\n",
    "#  The ROC-AUC score is high, suggesting that the model's ability to distinguish between classes is good.\n",
    "# All in all the model shows promising results in its ability to predict attrition however further tuning can improve and provide even better results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
